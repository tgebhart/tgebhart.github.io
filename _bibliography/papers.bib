---
---

@article{gebhart_flow,
  title={Go with the Flow? A Large-Scale Analysis of Health Care Delivery Networks in the United States Using Hodge Theory},
  author={Thomas Gebhart and Xiaojun Fu and Russell Funk},
  abstract={We employ combinatorial Hodge theory to study referral flows on care delivery networks.},
  journal={IEEE BigData 2021 Workshop on TDA Applications to Big Data},
  year={2021},
  html={https://arxiv.org/abs/2110.09637},
}

@article{gebhart_knowledge_sheaves,
  title={Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph Embedding},
  author={Thomas Gebhart and Jakob Hansen and Paul Schrater},
  abstract={A sheaf-theoretic perspective on knowedge graph embedding.},
  journal={arXiv preprint arXiv:2110.03789},
  year={2021},
  html={https://arxiv.org/abs/2110.03789},
}

@article{gebhart_unified,
  title={A Unified Paths Perspective for Pruning at Initialization},
  author={Thomas Gebhart and Udit Saxena and Paul Schrater},
  abstract={We introduce the Path Kernel as the data-independent factor in a decomposition of the Neural Tangent Kernel and show the global structure of the Path Kernel can be computed efficiently. This Path Kernel decomposition separates the architectural effects from the data-dependent effects within the Neural Tangent Kernel.},
  journal={arXiv preprint arXiv:2101.10552},
  year={2021},
  html={https://arxiv.org/abs/2101.10552},
}

@article{hansen_sheaf_nn,
  title={Sheaf Neural Networks},
  author={Jakob Hansen and Thomas Gebhart},
  abstract={We present a generalization of graph convolutional networks by generalizing the diffusion operation using the sheaf Laplacian.},
  journal={NeurIPS 2020 Workshop on Topological Data Analysis and Beyond},
  year={2020},
  html={https://arxiv.org/abs/2012.06333},
}

@article{gebhart2020characterizing,
  title={The Emergence of Higher-Order Structure in Scientific and Technological Knowledge Networks},
  author={Thomas Gebhart and Russell J. Funk},
  abstract={We use tools from algebraic topology to characterize the higher-order structure of knowledge networks in science and technology across scale and time.},
  journal={arXiv preprint arXiv:2009.13620},
  year={2020},
  html={https://arxiv.org/abs/2009.13620},
}

@article{chowdhury2019path,
  title={Path Homologies of Deep Feedforward Networks},
  author={Samir Chowhury and Thomas Gebhart and Steve Huntsman and Matvey Yutin},
  journal={Proceedings of the 18th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  abstract={We characterize two types directed homology--path homology and directed rips homology--with respect to feedforward neural networks' parameter connectivity.},
  year={2019},
  html={https://arxiv.org/abs/1910.07617},
  pdf={path_homologies_of_deep_feedforward_networks.pdf}
}

@article{gebhart2019characterizing,
  title={Characterizing the Shape of Activation Space in Deep Neural Networks},
  author={Thomas Gebhart and Paul Schrater, and Alan Hylton},
  journal={Proceedings of the 18th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  abstract={A method for computing persistent homology of activation space within neural networks. We also provide some empirical results about how this topological perspective can inform us about how neural networks process inputs.},
  year={2019},
  html={https://arxiv.org/abs/1901.09496},
  pdf={characterizing_the_shape_of_activation_space.pdf}
}

@article{tabet2019predicting,
  title={Applying SVM algorithms toward predicting hostâ€“guest interactions with cucurbit[7]uril},
  author={Anthony Tabet and Thomas Gebhart and Guanglu Wu and et al},
  journal={Physical Chemistry Chemical Physics},
  abstract={DFT, NMR, ITC, and cell confluence data are used to generate predictive algorithms of supramolecular binding to cucurbit[7]uril and experimentally validate these predictions.},
  year={2020},
  html={https://pubs.rsc.org/en/content/articlehtml/2020/cp/c9cp05800a},
}

@article{gebhart2017adversary,
  title={Adversary Detection in Neural Networks via Persistent Homology},
  author={Thomas Gebhart and Paul Schrater},
  abstract={We show that a multi-scale analysis of neural network activations is able to capture the existence of adversarial inputs within neural networks.},
  journal={arXiv preprint arXiv:1711.10056},
  year={2017},
  html={https://arxiv.org/abs/1711.10056},
}


# Talks

@talk{networks2021,
  title={Go with the Flow? A Large-Scale Analysis of Health Care Delivery Networks in the United States Using Hodge Theory},
  abstract={Presented (virtually) at IEEE BigData 2021},
  year={2021},
  pdf={go_with_the_flow_a_large_scale_analysis_of_health_care_delivery_networks_in_the_united_states_using_hodge_theory.pdf}
}

@talk{networks2021,
  title={Measuring Breakthrough Discovery and Invention with Algebraic Topology},
  abstract={Presented (virtually) at Networks 2021},
  year={2021},
  pdf={measuring_breakthrough_discovery_and_invention_with_algebraic_topology.pdf}
}

@talk{neurips2020,
  title={Sheaf Neural Networks},
  abstract={Presented (virtually) at the NeurIPS 2020 Workshop on TDA and Beyond},
  year={2020},
  pdf={talk_sheaf_neural_networks.pdf}
}

@talk{nsd2020,
  title={PCA, Dimensionality, and NSD},
  abstract={Presented (virtually) at the NSD Mini Conference August 2020.},
  year={2020},
  pdf={nsd_conference_aug2020.pdf}
}

@talk{phodn2019,
  title={Path Homologies of Deep Networks},
  abstract={Presented at ICMLA 2019},
  year={2019},
  pdf={talk_path_homologies_of_deep_feedforward_networks.pdf}
}

@talk{gtdaml2019,
  title={Analyzing Deep Neural Networks with Persistent Homology},
  abstract={Presented at GTDAML 2019},
  year={2019},
  pdf={Analyzing_deep_neural_networks_with_persistent_homology.pdf}
}

# Posters

@Poster{icmla2019,
  title={Characterizing the Shape of Activation Space in Deep Neural Networks},
  abstract={Poster at ICMLA 2019},
  year={2019},
}

@Poster{icmla2019,
  title={Topological Analysis of Neural Network Computations},
  abstract={Poster at CS&E Research Showcase},
  year={2017},
}
